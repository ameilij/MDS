{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Práctico 4.2\n",
    "\n",
    "* Antes de procesar los texto con cualquier algoritmo de aprendizaje automático (supervisado o no supervisado) es necesario realizar un preporcesamiento con el objetivo de limpiar, normalizar y estructurar el texto.\n",
    "\n",
    "\n",
    "* Para ello se propone el siguiente framework:\n",
    "\n",
    "\n",
    "<img src=\"./imgs/007_framework_preprocesamiento_texto.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "* Los pasos propuestos en este framework pueden abordarse en el orden que se quiera e incluso alguno de estas etapas no sería necesario realizarse en función de como tengamos los textos.\n",
    "\n",
    "\n",
    "* Definamos a continuación lo que hay que realizar en cada uno de estos pasos:\n",
    "\n",
    "\n",
    "1.- ***Eliminación de ruido***: \n",
    "\n",
    "   * Este paso tiene como objetivo eliminar todos aquellos símbolos o caracteres que no aportan nada en el significado de las frases (ojo no confundir con las stop-words), como por ejemplo etiquetas HTML (para el caso del scraping), parseos de XML, JSON, etc.\n",
    "    \n",
    "2.- ***Tokenización***: \n",
    "   * Este paso tiene como objetivo dividir las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
    "   * Aunque la tokenización es el proceso de dividir grandes cadenas de texto en cadenas más pequeñas, se suele diferenciar la:\n",
    "       * ***Segmentation***: Tarea de dividir grandes cadenas de texto en piezas más pequeñas como oraciones o párrafos.\n",
    "       * ***Tokenization***: Tarea de dividir grandes cadenas de texto solo y exclusivamente en palabras.\n",
    "    \n",
    "3.- ***Normalización***:\n",
    "\n",
    "   * La normalización es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones:\n",
    "        * Convertir todo el texto en mayúscula o minúsculas\n",
    "        * Eliminar, puntos, comas, comillas, etc.\n",
    "        * Convertir los números a su equivalente a palabras\n",
    "        * Quitar las Stop-words\n",
    "        * etc.\n",
    "        \n",
    "<hr>\n",
    "\n",
    "## Ejemplo de Preprocesamiento de Texto.\n",
    "\n",
    "\n",
    "* Aunque no hay una norma o guía de como realizar una normalización de texto ya que esta depende del problema a resolver y de la naturaleza del texto, vamos a mostrar a continuación algunas operaciones más o menos comúnes para la tokenización y normalización de los textos.\n",
    "\n",
    "\n",
    "* En el siguiente ejemplo vamos a tokenizar y normalizar un texto:\n",
    "    1. Transformar un texto en tokens\n",
    "    2. Eliminar los tokens que son signos (puntuación, exclamación, etc.)\n",
    "    3. Eliminar las palabras que tienen menos de 'N' caracteres\n",
    "    4. Eliminar las palabras que son Stop Words\n",
    "    5. Pasar el texto a minúsculas\n",
    "    6. Lematización\n",
    "    \n",
    "    \n",
    "* **Nota**: *la normalización de texto que se va a codificar a continuación puede codificarse de forma más optimizada sin la necesidad de recorrer tantas veces la lista de tokens. Ya que este es un ejemplo con fines didácticos, este se centra en los conceptos y no en la optimización*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    \"\"\"\n",
    "    Función que dado un texto devuelve una lista con las palabras del texto no vacias\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [word.text.strip() for word in doc if len(word.text.strip()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, elimina los signos de puntuación\n",
    "    \"\"\"\n",
    "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
    "    return [word.text for word in doc if not word.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_words(words, num_chars):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras y un número mínimo de caracteres que tienen que tener\n",
    "    las palabras, elimina todas las palabras que tengan menos caracteres que los indicados\n",
    "    \"\"\"\n",
    "    return [word for word in words if len(word) > num_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, elimina las Stop Words\n",
    "    \"\"\"\n",
    "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
    "    return [word.text for word in doc if not word.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, las transforma a minúsculas\n",
    "    \"\"\"\n",
    "    return [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer_DEPRECATED(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, devuelve esa lista con el lema de cada una de esas palabras\n",
    "    \"\"\"\n",
    "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
    "    return [word.lemma_ for word in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(words):\n",
    "    \"\"\"\n",
    "    Función que dada una lista de palabras, devuelve esa lista con el lema de cada una de esas palabras\n",
    "    \"\"\"\n",
    "    tempDocument = ' '.join(words)\n",
    "    # Opcional nlp = spacy.load(\"es_core_web_sm\")\n",
    "    tempDocument = nlp(tempDocument)\n",
    "    return [word.lemma_ for word in tempDocument]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \"\"\"\n",
    "    Dado un texto, devuelve el texto tokenizado y normalizado\n",
    "    \"\"\"\n",
    "    words = get_tokens(text=text)\n",
    "    words = remove_punctuation(words=words)\n",
    "    words = remove_short_words(words=words, num_chars=3)\n",
    "    words = remove_stop_words(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = lemmatizer(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasamos a tokenizar y normalizar el siguiente texto usando la función de normalización realizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fernando', 'alonso', 'vuelto', 'sacar', 'petróleo', 'carrera', 'salir', 'acabar', 'premio', 'coronado', 'adelantar', 'pista', 'sebastiar', 'vettel', 'líder', 'mundial', 'querido', 'sacar', 'pecho', 'coche', 'tocado', 'problema', 'dirección', 'claro', 'desventajo', 'perder', 'recta', 'imposible', 'adelantar él', 'conseguía', 'pillar él', 'aber', 'pensé', 'curir', 'poder', 'intentar', 'salir', 'contento', 'séptir', 'sumar', 'punto', 'carrera', 'señalado']\n"
     ]
    }
   ],
   "source": [
    "raw = \"\"\"Fernando Alonso ha vuelto a sacar petróleo de la carrera, saliendo 13º y acabando 7º un \n",
    "         gran premio que ha coronado adelantando en pista a Sebastian Vettel, líder del Mundial.\n",
    "         Aunque no ha querido sacar pecho por ello: \"Su coche estaba tocado, tenía problemas de dirección, \n",
    "         estaban en clara desventaja e iba perdiendo cada vez más, vi que en la recta iba a ser imposible \n",
    "         adelantarle incluso con el DRS no conseguía pillarle así que como se abría mucho pensé que en la \n",
    "         primera curva que pudiera lo intentaba por dentro y a la primera salió bien y creo que hay que \n",
    "         estar contentos, séptimos otra vez, sumando puntos en las tres carreras\", ha señalado.\"\"\"\n",
    "print(normalize(raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este ejemplo podemos ver como reducimos las palabras (tokens) del texto original, quedandonos con lo importante y normalizado\n",
    "#### Pasamos de 128 tokens del texto original a 44 tokens tras la normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens del texto original: 128\n",
      "Número de tokens distintos del texto original: 91\n",
      "Número de tokens tras la normalización: 43\n",
      "Número de tokens distintos tras la normalización: 40\n"
     ]
    }
   ],
   "source": [
    "print('Número de tokens del texto original: ' + str(len(get_tokens(raw))))\n",
    "print('Número de tokens distintos del texto original: ' + str(len(set(get_tokens(raw)))))\n",
    "print('Número de tokens tras la normalización: ' + str(len(normalize(raw))))\n",
    "print('Número de tokens distintos tras la normalización: ' + str(len(set(normalize(raw)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1: Get Tokens.\n",
      "['El', 'Tribunal', 'Electoral', '(', 'TE', ')', 'ha', 'recordado', 'a', 'los', 'partidos', 'políticos', 'y', 'a', 'todos', 'los', 'que', 'aspiran', 'a', 'cargos', 'de', 'elección', 'popular', 'por', 'la', 'libre', 'postulación', 'que', 'estamos', 'en', 'un', 'período', 'de', 'veda', 'electoral', ',', 'en', 'la', 'que', 'las', 'manifestaciones', 'populares', 'o', 'la', 'propaganda', 'está', 'prohibida', '.', 'No', 'obstante', ',', 'hay', 'políticos', 'que', 'burlan', 'la', 'prohibición', 'con', 'creativos', 'métodos', 'que', 'hacen', 'posible', 'hacer', 'campaña', 'sin', 'la', 'aparente', 'violación', 'de', 'las', 'normas', '.', 'Estas', 'nuevas', 'fórmulas', 'deberían', 'ser', 'identificadas', 'por', 'la', 'Fiscalía', 'Electoral', 'para', 'someterlas', '...']\n"
     ]
    }
   ],
   "source": [
    "# No funciona el programa, veamos que pasa si lo hacemos a mano\n",
    "texto = \"\"\"El Tribunal Electoral (TE) ha recordado a los partidos políticos y a todos los que aspiran a cargos de elección popular por la \n",
    "libre postulación que estamos en un período de veda electoral, en la que las manifestaciones populares o la propaganda está prohibida. \n",
    "No obstante, hay políticos que burlan la prohibición con creativos métodos que hacen posible hacer campaña sin la aparente violación de \n",
    "las normas. Estas nuevas fórmulas deberían ser identificadas por la Fiscalía Electoral para someterlas...\"\"\"\n",
    "\n",
    "print(\"Paso 1: Get Tokens.\")\n",
    "temp = get_tokens(text=texto)\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 2: Eliminar puntuacion.\n",
      "['El', 'Tribunal', 'Electoral', 'TE', 'ha', 'recordado', 'a', 'los', 'partidos', 'políticos', 'y', 'a', 'todos', 'los', 'que', 'aspiran', 'a', 'cargos', 'de', 'elección', 'popular', 'por', 'la', 'libre', 'postulación', 'que', 'estamos', 'en', 'un', 'período', 'de', 'veda', 'electoral', 'en', 'la', 'que', 'las', 'manifestaciones', 'populares', 'o', 'la', 'propaganda', 'está', 'prohibida', 'No', 'obstante', 'hay', 'políticos', 'que', 'burlan', 'la', 'prohibición', 'con', 'creativos', 'métodos', 'que', 'hacen', 'posible', 'hacer', 'campaña', 'sin', 'la', 'aparente', 'violación', 'de', 'las', 'normas', 'Estas', 'nuevas', 'fórmulas', 'deberían', 'ser', 'identificadas', 'por', 'la', 'Fiscalía', 'Electoral', 'para', 'someterlas']\n"
     ]
    }
   ],
   "source": [
    "print(\"Paso 2: Eliminar puntuacion.\")\n",
    "temp2 = remove_punctuation(words=temp)\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 3: Eliminar N-Gramas\n",
      "['Tribunal', 'Electoral', 'recordado', 'partidos', 'políticos', 'todos', 'aspiran', 'cargos', 'elección', 'popular', 'libre', 'postulación', 'estamos', 'período', 'veda', 'electoral', 'manifestaciones', 'populares', 'propaganda', 'está', 'prohibida', 'obstante', 'políticos', 'burlan', 'prohibición', 'creativos', 'métodos', 'hacen', 'posible', 'hacer', 'campaña', 'aparente', 'violación', 'normas', 'Estas', 'nuevas', 'fórmulas', 'deberían', 'identificadas', 'Fiscalía', 'Electoral', 'para', 'someterlas']\n"
     ]
    }
   ],
   "source": [
    "print(\"Paso 3: Eliminar N-Gramas\")\n",
    "temp3 = remove_short_words(words=temp2, num_chars=3)\n",
    "print(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 4: Eliminar Stop Words.\n",
      "['Tribunal', 'Electoral', 'recordado', 'partidos', 'políticos', 'aspiran', 'cargos', 'elección', 'popular', 'libre', 'postulación', 'período', 'veda', 'electoral', 'manifestaciones', 'populares', 'propaganda', 'prohibida', 'obstante', 'políticos', 'burlan', 'prohibición', 'creativos', 'métodos', 'campaña', 'aparente', 'violación', 'normas', 'fórmulas', 'deberían', 'identificadas', 'Fiscalía', 'Electoral', 'someterlas']\n"
     ]
    }
   ],
   "source": [
    "print(\"Paso 4: Eliminar Stop Words.\")\n",
    "temp4 = remove_stop_words(temp3)\n",
    "print(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 5: Todo a Minuscula.\n",
      "['tribunal', 'electoral', 'recordado', 'partidos', 'políticos', 'aspiran', 'cargos', 'elección', 'popular', 'libre', 'postulación', 'período', 'veda', 'electoral', 'manifestaciones', 'populares', 'propaganda', 'prohibida', 'obstante', 'políticos', 'burlan', 'prohibición', 'creativos', 'métodos', 'campaña', 'aparente', 'violación', 'normas', 'fórmulas', 'deberían', 'identificadas', 'fiscalía', 'electoral', 'someterlas']\n"
     ]
    }
   ],
   "source": [
    "print(\"Paso 5: Todo a Minuscula.\")\n",
    "temp5 = to_lowercase(temp4)\n",
    "print(temp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 6: Lamentizar.\n",
      "['tribunal', 'electoral', 'recordado', 'partido', 'político', 'aspirar', 'cargo', 'elección', 'popular', 'libre', 'postulación', 'período', 'vedir', 'electoral', 'manifestación', 'popular', 'propaganda', 'prohibido', 'obstante', 'político', 'burlar', 'prohibición', 'creativo', 'método', 'campaña', 'aparente', 'violación', 'norma', 'fórmula', 'deber', 'identificado', 'fiscalía', 'electoral', 'someter él']\n"
     ]
    }
   ],
   "source": [
    "print(\"Paso 6: Lamentizar.\")\n",
    "temp6 = lemmatizer(temp5)\n",
    "print(temp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
